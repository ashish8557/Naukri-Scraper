{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87e7de58-b785-4482-842d-9e6dfdee1155",
   "metadata": {},
   "source": [
    "# Naukri Web Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab2c7c3-28e6-49b7-ad96-dfd3c5e274ee",
   "metadata": {},
   "source": [
    "### Naukri Web Scraping is the project based on scraping jobs post related to any domains and their details. It also analyse the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177e049d-58a5-4762-9f81-9f32c197cd32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cell 1: Imports\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "import time\n",
    "import re\n",
    "\n",
    "# Show plots inline\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ee7b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Initialize WebDriver\n",
    "def initialize_driver():\n",
    "    \"\"\"Initializes and returns a Firefox WebDriver.\"\"\"\n",
    "    driver = webdriver.Firefox()\n",
    "    return driver\n",
    "\n",
    "driver = initialize_driver()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a9a423-046a-4cf3-bb37-7c4c885e6add",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cell 3: Scraping Function (customizable role + pages)\n",
    "def scrape_naukri_jobs(driver, job_role, num_pages):\n",
    "    \"\"\"\n",
    "    Scrape job data from Naukri.com for a given role and number of pages.\n",
    "    \n",
    "    Args:\n",
    "        driver: Selenium WebDriver\n",
    "        job_role (str): Job keyword/role to search (e.g., \"python tester\")\n",
    "        num_pages (int): Number of pages to scrape\n",
    "    \n",
    "    Returns:\n",
    "        dict: Scraped job data\n",
    "    \"\"\"\n",
    "    jobs = {\n",
    "        \"job_no\": [],\n",
    "        \"roles\": [],\n",
    "        \"companies\": [],\n",
    "        \"locations\": [],\n",
    "        \"experience\": [],\n",
    "        \"salaries\": [],\n",
    "        \"skills\": []\n",
    "    }\n",
    "\n",
    "    job_role = job_role.replace(\" \", \"-\")  # URL-friendly\n",
    "\n",
    "    for i in range(num_pages):\n",
    "        url = f\"https://www.naukri.com/{job_role}-jobs-{i}\"\n",
    "        print(f\"Scraping page {i+1}/{num_pages}: {url}\")\n",
    "        driver.get(url)\n",
    "        time.sleep(3)\n",
    "\n",
    "        lst = driver.find_elements(By.CLASS_NAME, \"srp-jobtuple-wrapper\")\n",
    "\n",
    "        for index, job in enumerate(lst):\n",
    "            driver.implicitly_wait(2)\n",
    "            jobno = (i * len(lst) + index + 1)\n",
    "\n",
    "            try:\n",
    "                role = job.find_element(By.CLASS_NAME, \"title\").text\n",
    "                company = job.find_element(By.CLASS_NAME, \"comp-name\").text\n",
    "                location = job.find_element(By.CLASS_NAME, \"loc-wrap\").text\n",
    "                exp = job.find_element(By.CLASS_NAME, \"exp-wrap\").text\n",
    "\n",
    "                # Salary (optional)\n",
    "                salary_elements = job.find_elements(By.CLASS_NAME, \"sal-wrap\")\n",
    "                salary = salary_elements[0].text if salary_elements else \"NA\"\n",
    "\n",
    "                # Skills (optional)\n",
    "                skill_elements = job.find_elements(By.CSS_SELECTOR, \".tags-gt li\")\n",
    "                skill = \",\".join([li.text for li in skill_elements]) if skill_elements else \"NA\"\n",
    "\n",
    "                jobs[\"job_no\"].append(jobno)\n",
    "                jobs[\"roles\"].append(role)\n",
    "                jobs[\"companies\"].append(company)\n",
    "                jobs[\"locations\"].append(location)\n",
    "                jobs[\"experience\"].append(exp)\n",
    "                jobs[\"salaries\"].append(salary)\n",
    "                jobs[\"skills\"].append(skill)\n",
    "\n",
    "            except NoSuchElementException:\n",
    "                continue\n",
    "    return jobs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b0664f-1978-43a6-845f-3f64eef9fc11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cell 4: Process Data\n",
    "def process_job_data(jobs_data):\n",
    "    df_raw = pd.DataFrame.from_dict(jobs_data)\n",
    "    df_raw = df_raw.apply(lambda x: x.astype(str).str.lower())\n",
    "\n",
    "    # Split locations and skills\n",
    "    df_raw['skills'] = [skill.split(\",\") for skill in df_raw['skills']]\n",
    "    df_raw['locations'] = [location.split(\",\") for location in df_raw['locations']]\n",
    "\n",
    "    # Clean salaries and experience\n",
    "    df_raw['salaries'] = df_raw['salaries'].str.replace(' lacs pa', '', regex=False)\n",
    "    df_raw['experience'] = df_raw['experience'].str.replace(' yrs', '', regex=False)\n",
    "\n",
    "    return df_raw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d87d913-f1f9-4547-97ad-efb9d4317311",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cell 5: Analysis Functions\n",
    "def analyze_experience(df):\n",
    "    print(\"\\nüìä Experience Analysis\")\n",
    "    experience_counts = df['experience'].value_counts()\n",
    "    display(experience_counts.head(10))\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    experience_counts.head(10).plot(kind='bar', color='skyblue')\n",
    "    plt.title('Experience Range')\n",
    "    plt.show()\n",
    "\n",
    "def analyze_salary(df):\n",
    "    print(\"\\nüìä Salary Analysis\")\n",
    "    salaries_counts = df['salaries'].value_counts()\n",
    "    display(salaries_counts.head(10))\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    salaries_counts.head(10).plot(kind='bar', color='orange')\n",
    "    plt.title('Salary Range')\n",
    "    plt.show()\n",
    "\n",
    "def clean_and_analyze_locations(df):\n",
    "    print(\"\\nüìä Location Analysis\")\n",
    "    df_location = df.assign(Values=df['locations'].str.split(',')).explode('locations')\n",
    "    df_location = df_location[['job_no', 'locations']]\n",
    "\n",
    "    # Basic cleaning\n",
    "    df_location['locations'] = df_location['locations'].apply(lambda x: re.sub(r'\\(.*\\)|hybrid\\s*-\\s*|\\bnew\\s|\\s*|/.*$', '', x).strip())\n",
    "\n",
    "    # Normalization\n",
    "    df_location['locations'] = df_location['locations'].str.replace(r'\\b\\w*mumbai\\w*\\b', 'mumbai', regex=True)\n",
    "    df_location['locations'] = df_location['locations'].str.replace(r'\\b\\w*delhi\\w*\\b', 'delhi', regex=True)\n",
    "    df_location['locations'] = df_location['locations'].str.replace(r'\\b\\w*bangal\\w*\\b', 'bengaluru', regex=True)\n",
    "    df_location['locations'] = df_location['locations'].str.replace(r'\\b\\w*noida\\w*\\b', 'noida', regex=True)\n",
    "\n",
    "    location_counts = df_location['locations'].value_counts()\n",
    "    display(location_counts.head(10))\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    location_counts.head(10).plot(kind='bar', color='skyblue')\n",
    "    plt.title('Job Locations')\n",
    "    plt.show()\n",
    "\n",
    "    # Wordcloud\n",
    "    location_string = ', '.join(df_location['locations'].dropna())\n",
    "    wordcloud = WordCloud(width=800, height=400, background_color='white').generate(location_string)\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def analyze_skills(df):\n",
    "    print(\"\\nüìä Skills Analysis\")\n",
    "    df_skills = df.assign(Values=df['skills'].str.split(',')).explode('skills')\n",
    "    df_skills = df_skills[['job_no', 'skills']]\n",
    "\n",
    "    distinct_skill = df_skills['skills'].unique()\n",
    "    print(f\"Total distinct skills: {len(distinct_skill)}\")\n",
    "\n",
    "    # Wordcloud\n",
    "    skills_string = ', '.join(df_skills['skills'].dropna())\n",
    "    wordcloud = WordCloud(width=800, height=400, background_color='white').generate(skills_string)\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21c7013-f88e-4737-8287-5df4a82e8dc5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cell 6: Run Scraper (choose role & pages here)\n",
    "job_role = \"python tester\"   # üîπ Change this to any job role (e.g. \"selenium\", \"qa automation\")\n",
    "num_pages = 1               # üîπ Change this for number of pages to scrape\n",
    "\n",
    "jobs_data = scrape_naukri_jobs(driver, job_role=job_role, num_pages=num_pages)\n",
    "\n",
    "if jobs_data[\"job_no\"]:\n",
    "    df_raw = process_job_data(jobs_data)\n",
    "    display(df_raw.head())\n",
    "    df_raw.to_csv(f'Naukri_{job_role.replace(\" \",\"_\")}.csv', index=False)\n",
    "    print(f\"‚úÖ Raw data saved as Naukri_{job_role.replace(' ','_')}.csv\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No jobs scraped\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c92ceb-acf3-45c9-b057-9a28671d6246",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cell 7: Run Detailed Analysis\n",
    "analyze_experience(df_raw)\n",
    "analyze_salary(df_raw)\n",
    "clean_and_analyze_locations(df_raw)\n",
    "analyze_skills(df_raw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2464e2-58f4-4433-8159-2c765bcd04c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cell 8: Close WebDriver\n",
    "driver.quit()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".ashivenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": true,
  "toc-showtags": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
